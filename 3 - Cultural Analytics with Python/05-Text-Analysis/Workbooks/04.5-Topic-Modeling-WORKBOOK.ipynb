{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Part 2 Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these lessons, we're learning about a text analysis method called *topic modeling*. This method will help us identify the main topics or discourses within a collection of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular lesson, we're going to use [Little MALLET Wrapper](https://github.com/maria-antoniak/little-mallet-wrapper), a Python wrapper for [MALLET](http://mallet.cs.umass.edu/topics.php), to topic model a CSV file with 2,932 Reddit posts from the subreddit [r/AmITheAsshole](https://www.reddit.com/r/AmItheAsshole/) that have at least an upvote score of 2,000. This is an online forum where people share their personal conflicts and ask the community to judge who's the a**hole in the story. This data was collected with PSAW, a wrapper for the Pushshift API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Java/Mallet Work on Your Computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have the Java Development Kit installed and configured properly? Test it out by running this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!javac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you get a long message, `Usage: javac <options> <source files>...`, then JDK is installed and set up!  \n",
    "- If you get some version of the message, `javac: command not found`, then it is not installed or configured properly. If you're a Mac user, make sure you installed and donwloaded the JDK. If you're a Windows user, make sure you installed and downloaded the JDK and then changed your PATH enviornment variable, [as described here](https://info1350.github.io/Intro-CA-SP21/05-Text-Analysis/06-Topic-Modeling-Set-Up.html#windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to locate the correct filepath for Mallet. Where is Mallet downloaded and installed on your computer?\n",
    "\n",
    "Mac users should be able to use the version of Mallet in this directory, i.e. `mallet-2.0.8/bin/mallet`. Windows users need to have an environment variable for the Mallet filepath, as described here, so it may be set up somewhere else, i.e. `C:/mallet-2.0.8/bin/mallet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also discovered that you may need to give explicit permission to the Mallet filepath, which you can do with the `chmod +x` command below (see [\"Setting Permissions,\"](https://launchschool.com/books/command_line/read/permissions#settingpermissions) The Launch School). Be sure to replace the filepaths below with your correct filepath for Mallet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow execute permissions for Mallet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x mallet-2.0.8/bin/mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if Mallet is recognized and working (if you get the message \"A tool for creating instance lists of feature vectors from comma-separated-values...\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mallet-2.0.8/bin/mallet import-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Mallet is recognized and working above, set `path_to_mallet` to that exact filepath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mallet = 'mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `little_mallet_wrapper` and the data viz library `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install little_mallet_wrapper\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's `import` the `little_mallet_wrapper` and the data viz library `seaborn`. We're also going to import `pandas` and [`pathlib`](https://docs.python.org/3/library/pathlib.html#basic-use) for working with files and the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import little_mallet_wrapper\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data From CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we topic model the Reddit posts, we need to process the posts and prepare them for analysis. The steps below demonstrate how to process texts if they come from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"../data/top-reddit-aita-posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `selftext` column to a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['selftext'] = reddit_df['selftext'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Reddit Posts and Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to process our texts with the function `little_mallet_wrapper.process_string()`.\n",
    "\n",
    "This function will take every individual post, transform all the text to lowercase as well as remove stopwords, punctuation, and numbers, and then add the processed text to our master list `training_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [little_mallet_wrapper.process_string(text, numbers='remove') for text in reddit_df['selftext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to make a list of the original texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = [text for text in reddit_df['selftext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to extract the file name for each Reddit post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_titles = [title for title in reddit_df['title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make a variable `num_topics` and assign it the number of topics we want returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Topic Model Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to tell Little MALLET Wrapper where to find and output all of our topic modeling results. The code below will set Little MALLET Wrapper up to output your results inside a directory called \"topic-model-output\" and a subdirectory called \"NYT-Obits\", all of which will be inside your current directory.\n",
    "\n",
    "If you'd like to change this output location, simply change `output_directory_path` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training data (our pre-processed text files)\n",
    "training_data = training_data\n",
    "\n",
    "#Change to your desired output directory\n",
    "output_directory_path = 'topic-model-output/Reddit-Workbook'\n",
    "\n",
    "#No need to change anything below here\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our topic model with `little_mallet_wrapper.quick_train_topic_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_mallet = 'mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "little_mallet_wrapper.quick_train_topic_model(path_to_mallet,\n",
    "                                              output_directory_path,\n",
    "                                              num_topics,\n",
    "                                              training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Topics and Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the `little_mallet_wrapper.load_topic_keys()` function to read and process the MALLET topic model output from your computer, specifically the file \"mallet.topic_keys.15\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "for topic_number, topic in enumerate(topics):\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Topic Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the topic distributions, we're going to use the `little_mallet_wrapper.load_topic_distributions()` function, which will read and process the MALLET topic model output, specifically the file \"mallet.topic_distributions.15\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Top Titles Per Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the obituaries that have the highest probability for every topic with the `little_mallet_wrapper.get_top_docs()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we `zip` together the training data (pre-processed docs) and list of titles, as well as the training data and list of original texts. Then we turn them into dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_reddit_titles = dict(zip(training_data, reddit_titles))\n",
    "training_data_original_text = dict(zip(training_data, original_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll make our own function `display_top_titles_per_topic()` that will display the top text titles for every topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_titles_per_topic(topic_number=0, number_of_documents=5):\n",
    "    \n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        print(round(probability, 4), training_data_reddit_titles[document] + \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 5 obituary titles with the highest probability of containing Topic 0, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_titles_per_topic(topic_number=0, number_of_documents=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Topic Words in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the original obituary texts that rank highly for a given topic, with the relevant topic words **bolded** for emphasis, we are going to make the function `display_bolded_topic_words_in_context()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def display_bolded_topic_words_in_context(topic_number=3, number_of_documents=3, custom_words=None):\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        \n",
    "        print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "        \n",
    "        probability = f\"✨✨✨\\n\\n**{probability}**\"\n",
    "        obit_title = f\"**{training_data_reddit_titles[document]}**\"\n",
    "        original_text = training_data_original_text[document]\n",
    "        topic_words = topics[topic_number]\n",
    "        topic_words = custom_words if custom_words != None else topic_words\n",
    "\n",
    "        for word in topic_words:\n",
    "            if word in original_text:\n",
    "                original_text = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word}**\", original_text)\n",
    "\n",
    "        display(Markdown(probability)), display(Markdown(obit_title)), display(Markdown(original_text))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the top 3 Reddit posts with the highest probability of containing Topic 0 and with relevant topic words bolded, we will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "display_bolded_topic_words_in_context(topic_number=0, number_of_documents=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your group, come up with labels for the select topics below. For this exercise, we will all use the exact same topic model results, which can be found in `topic-model-output/Reddit-Class-Version`.\n",
    "\n",
    "Run the cells below to load the class version of our topic model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_path_class = 'topic-model-output/Reddit-Class-Version'\n",
    "\n",
    "path_to_topic_keys_class              = f\"{output_directory_path_class}/mallet.topic_keys.15\"\n",
    "path_to_topic_distributions_class     = f\"{output_directory_path_class}/mallet.topic_distributions.15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys_class)\n",
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics to Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 0**: 'time', 'work', 'get', 'day', 'going', 'home'  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 1**: 'name', 'friends', 'people', 'post', 'even', 'group'  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 2**: 'family', 'brother', 'years', 'parents', 'sister'  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 3**: 'food', 'eat', 'dinner', 'eating', 'one'   \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 5**: 'like', 'really', 'doesn', 'think', 'things'    \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 6**: 'money', 'pay', 'would', 'get', 'buy', 'since'   \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 12**: 'husband', 'kids', 'dog', 'said', 'home'  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 14**: 'car', 'back', 'get', 'didn', 'got', 'said'  \n",
    "**Topic Label**: ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To come up with a label for each topic, examine the top Reddit post titles for that topic as well as the words in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: To use the functions below, you need to have run most of the cells above, except for the `quick_train_topic_model()` cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_titles_per_topic(topic_number=0, number_of_documents=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_bolded_topic_words_in_context(topic_number=0, number_of_documents=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
