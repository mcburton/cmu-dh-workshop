{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis — Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to learn how to use [VADER](https://github.com/cjhutto/vaderSentiment) (Valence Aware Dictionary and sEntiment Reasoner), a sentiment analysis tool designed for social media. (Read the VADER paper [here](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/view/8109/8122).)\n",
    "\n",
    "We're going to see how well VADER works with our own sentences and with sentences from *The House on Mango Street*. Can we create an accurate plot arc of Sandra Cisneros's coming-of-age novel?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Libraries/Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and set Pandas display column width to 400 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install [vaderSentiment package](https://github.com/cjhutto/vaderSentiment) with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `SentimentIntensityAnalyser` and initlaize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sentimentAnalyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sentiment Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate sentiment scores for a sentence or paragraph, we can use the `.polarity_scores()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyser.polarity_scores(\"I like the Marvel movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyser.polarity_scores(\"I don't like the Marvel movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalyser.polarity_scores(\"I don't *not* like the Marvel movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the `sentimentAnalyzer` on some sentences of your own!\n",
    "\n",
    "Experiment with capitalization, punctuation, emojis, historical words, slangy language, poetry, or non-English words. How does VADER handle it? What does VADER seem to do well and not so well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sentiment Scores for *The House on Mango Street*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate sentiment scores for *The House on Mango Street*, we first need a quick-and-easy way to break the novel up into sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install [NLTK](https://www.nltk.org/), a Python library for text analysis natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import nltk and download the model that will help us get sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text and Break Into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the text file for \"Hairs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"../texts/literature/House-on-Mango-Street/02-Hairs.txt\"\n",
    "chapter = open(text_file, encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"../texts/literature/\"\n",
    "chapter = open(text_file, encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "number_of_chunks = 12\n",
    "\n",
    "chunk_size = math.ceil(len(text) / number_of_chunks)\n",
    "\n",
    "text_chunks = []\n",
    "\n",
    "for number in range(0, len(text), chunk_size):\n",
    "    text_chunk = text[number:number+chunk_size]\n",
    "    text_chunks.append(text_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To break a string into individual sentences, we can use `nltk.sent_tokenize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Scores for Each Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop through the sentences and calculate sentiment scores for every sentence.\n",
    "\n",
    "*How would we print just the \"compound\" score for each sentence?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    scores = sentimentAnalyser.polarity_scores(sentence)\n",
    "    \n",
    "    print(sentence, '\\n', scores, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convenient way to make a DataFrame is to first make a list of dictionaries.\n",
    "\n",
    "Below we loop through the sentences, calculate sentiment scores, and then create a mini-dictionary with the sentence and compound score, which we append to the list `sentence_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = []\n",
    "for sentence in sentences:\n",
    "    scores = sentimentAnalyser.polarity_scores(sentence)\n",
    "    sentence_scores.append({'sentence': sentence, 'score': scores['compound']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this list of dictionaries into a DataFrame, we can simply use `pd.DataFrame()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentence_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the sentences from negative to positive sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hairs_df = pd.DataFrame(sentence_scores)\n",
    "hairs_df.sort_values(by='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sentiment Scores By Chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate sentiment scores for the sentences in each chapter of *The House on Mango Street*, we need to read in each file indviidually.\n",
    "\n",
    "Below we will import `glob` and `Path`, which will allow us to get all the filenames for the chapters and extract the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of filenames for every `.txt` file in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../texts/literature/House-on-Mango-Street/\"\n",
    "text_files = glob.glob(f\"{directory_path}/*.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each file in the \"House on Mango Street\" directory, calculate sentiment scores, and make a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = []\n",
    "\n",
    "# Loop through all the filenames\n",
    "for text_file in text_files:\n",
    "    \n",
    "    #Read in the file\n",
    "    chapter = open(text_file, encoding=\"utf-8\").read()\n",
    "    #Extract the end of the filename\n",
    "    title = Path(text_file).stem\n",
    "    \n",
    "    #Loop through each sentence in the \n",
    "    for sentence in nltk.sent_tokenize(chapter):\n",
    "        #Calculate sentiment scores for sentence\n",
    "        scores = sentimentAnalyser.polarity_scores(sentence)\n",
    "        \n",
    "        #Make mini-dictionary with chapter name, sentence, and sentiment score\n",
    "        sentence_scores.append({'chapter': title,\n",
    "                                'sentence': sentence,\n",
    "                                'score': scores['compound']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a DataFrame from our list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df = pd.DataFrame(sentence_scores)\n",
    "# Make the DataFrame alphabetical by chapter\n",
    "chapter_df = chapter_df.sort_values(by='chapter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we examine the most negative 15 sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we examine the most positive 15 sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Plot Arc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a data visualization of sentiment over the course of *The House on Mango Street*, we first need to calculate the average sentiment for each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df.groupby('chapter')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_means = chapter_df.groupby('chapter')['score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chapter_means.plot(x='chapter', y='score', kind='bar',\n",
    "                        figsize=(13,10), rot=90, title='Sentiment in Mango Street')\n",
    "\n",
    "# Plot a horizontal line at 0\n",
    "plt.axhline(y=0, color='orange', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chapter_means.plot(x='chapter', y='score', kind='line',\n",
    "                        figsize=(13,10), rot=90, title='Sentiment in Mango Street')\n",
    "\n",
    "#Not all xtick labels will show up in a line plot by default, so we have to make it explicit\n",
    "ax.set_xticks(range(0, 44))\n",
    "ax.set_xticklabels(chapter_means['chapter'].unique())\n",
    "\n",
    "# Plot a horizontal line at 0\n",
    "plt.axhline(y=0, color='orange', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do these plot arcs align with your reading experience of *The House on Mango Street*? Examine some specific chapters and sentences below, and discuss how well VADER seems to be working or not working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if you want to read the sentences in order, you can use the `.sort_index()` method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chapter_df[chapter_df['chapter'].str.contains('Papa-Who')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine another chapter or chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chapter_df[chapter_df['chapter'].str.contains('INSERT-PART-OF-CHAPTER-NAME')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How well do you think VADER sentiment analysis works with literary texts?\n",
    "- How do social media posts and literary texts different in the way they express sentiment? (What is \"sentiment\", anyway?)\n",
    "- Could you imagine using sentiment analysis in a project? If so, how?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
